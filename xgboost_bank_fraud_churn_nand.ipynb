{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction with XGBoost\n",
    "_**Using Gradient Boosted Trees to Predict Mobile Customer Departure**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "  1. [Evaluate](#Evaluate)\n",
    "  1. [Relative cost of errors](#Relative-cost-of-errors)\n",
    "1. [Extensions](#Extensions)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "_This notebook has been adapted from an [AWS blog post](https://aws.amazon.com/blogs/ai/predicting-customer-churn-with-amazon-machine-learning/)_\n",
    "\n",
    "Losing customers is costly for any business.  Identifying unhappy customers early on gives you a chance to offer them incentives to stay.  This notebook describes using machine learning (ML) for the automated identification of unhappy customers, also known as customer churn prediction. ML models rarely give perfect predictions though, so this notebook is also about how to incorporate the relative costs of prediction mistakes when determining the financial outcome of using ML.\n",
    "\n",
    "We use an example of churn that is familiar to all of us–leaving a mobile phone operator.  Seems like I can always find fault with my provider du jour! And if my provider knows that I’m thinking of leaving, it can offer timely incentives–I can always use a phone upgrade or perhaps have a new feature activated–and I might just stick around. Incentives are often much more cost effective than losing and reacquiring a customer.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "bucket = 'anomaly-detection-files'\n",
    "prefix = 'sagemaker/xgboost-bankfraud'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the Python libraries we'll need for the remainder of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "Mobile operators have historical records on which customers ultimately ended up churning and which continued using the service. We can use this historical information to construct an ML model of one mobile operator’s churn using a process called training. After training the model, we can pass the profile information of an arbitrary customer (the same profile information that we used to train the model) to the model, and have the model predict whether this customer is going to churn. Of course, we expect the model to make mistakes–after all, predicting the future is tricky business! But I’ll also show how to deal with prediction errors.\n",
    "\n",
    "The dataset we use is publicly available and was mentioned in the book [Discovering Knowledge in Data](https://www.amazon.com/dp/0470908742/) by Daniel T. Larose. It is attributed by the author to the University of California Irvine Repository of Machine Learning Datasets.  Let's download and read that dataset in now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-02 14:56:58--  https://s3.amazonaws.com/nand-aws-ml/PS_20174392719_1491204439457_log.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.146.53\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.146.53|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 76688100 (73M) [text/csv]\n",
      "Saving to: ‘PS_20174392719_1491204439457_log.csv.17’\n",
      "\n",
      "PS_20174392719_1491 100%[===================>]  73.13M  64.2MB/s    in 1.1s    \n",
      "\n",
      "2019-05-02 14:56:59 (64.2 MB/s) - ‘PS_20174392719_1491204439457_log.csv.17’ saved [76688100/76688100]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/nand-aws-ml/PS_20174392719_1491204439457_log.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.00</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.00</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.00</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>7817.71</td>\n",
       "      <td>C90045638</td>\n",
       "      <td>53860.00</td>\n",
       "      <td>46042.29</td>\n",
       "      <td>M573487274</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>7107.77</td>\n",
       "      <td>C154988899</td>\n",
       "      <td>183195.00</td>\n",
       "      <td>176087.23</td>\n",
       "      <td>M408069119</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>7861.64</td>\n",
       "      <td>C1912850431</td>\n",
       "      <td>176087.23</td>\n",
       "      <td>168225.59</td>\n",
       "      <td>M633326333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>4024.36</td>\n",
       "      <td>C1265012928</td>\n",
       "      <td>2671.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M1176932104</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>5337.77</td>\n",
       "      <td>C712410124</td>\n",
       "      <td>41720.00</td>\n",
       "      <td>36382.23</td>\n",
       "      <td>C195600860</td>\n",
       "      <td>41898.00</td>\n",
       "      <td>40348.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>9644.94</td>\n",
       "      <td>C1900366749</td>\n",
       "      <td>4465.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C997608398</td>\n",
       "      <td>10845.00</td>\n",
       "      <td>157982.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>3099.97</td>\n",
       "      <td>C249177573</td>\n",
       "      <td>20771.00</td>\n",
       "      <td>17671.03</td>\n",
       "      <td>M2096539129</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>2560.74</td>\n",
       "      <td>C1648232591</td>\n",
       "      <td>5070.00</td>\n",
       "      <td>2509.26</td>\n",
       "      <td>M972865270</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11633.76</td>\n",
       "      <td>C1716932897</td>\n",
       "      <td>10127.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M801569151</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>4098.78</td>\n",
       "      <td>C1026483832</td>\n",
       "      <td>503264.00</td>\n",
       "      <td>499165.22</td>\n",
       "      <td>M1635378213</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>229133.94</td>\n",
       "      <td>C905080434</td>\n",
       "      <td>15325.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C476402209</td>\n",
       "      <td>5083.00</td>\n",
       "      <td>51513.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1563.82</td>\n",
       "      <td>C761750706</td>\n",
       "      <td>450.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M1731217984</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1157.86</td>\n",
       "      <td>C1237762639</td>\n",
       "      <td>21156.00</td>\n",
       "      <td>19998.14</td>\n",
       "      <td>M1877062907</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>671.64</td>\n",
       "      <td>C2033524545</td>\n",
       "      <td>15123.00</td>\n",
       "      <td>14451.36</td>\n",
       "      <td>M473053293</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>215310.30</td>\n",
       "      <td>C1670993182</td>\n",
       "      <td>705.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1100439041</td>\n",
       "      <td>22425.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1373.43</td>\n",
       "      <td>C20804602</td>\n",
       "      <td>13854.00</td>\n",
       "      <td>12480.57</td>\n",
       "      <td>M1344519051</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>9302.79</td>\n",
       "      <td>C1566511282</td>\n",
       "      <td>11299.00</td>\n",
       "      <td>1996.21</td>\n",
       "      <td>C1973538135</td>\n",
       "      <td>29832.00</td>\n",
       "      <td>16896.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>1065.41</td>\n",
       "      <td>C1959239586</td>\n",
       "      <td>1817.00</td>\n",
       "      <td>751.59</td>\n",
       "      <td>C515132998</td>\n",
       "      <td>10330.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>3876.41</td>\n",
       "      <td>C504336483</td>\n",
       "      <td>67852.00</td>\n",
       "      <td>63975.59</td>\n",
       "      <td>M1404932042</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>311685.89</td>\n",
       "      <td>C1984094095</td>\n",
       "      <td>10835.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C932583850</td>\n",
       "      <td>6267.00</td>\n",
       "      <td>2719172.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>6061.13</td>\n",
       "      <td>C1043358826</td>\n",
       "      <td>443.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M1558079303</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9478.39</td>\n",
       "      <td>C1671590089</td>\n",
       "      <td>116494.00</td>\n",
       "      <td>107015.61</td>\n",
       "      <td>M58488213</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>8009.09</td>\n",
       "      <td>C1053967012</td>\n",
       "      <td>10968.00</td>\n",
       "      <td>2958.91</td>\n",
       "      <td>M295304806</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>8901.99</td>\n",
       "      <td>C1632497828</td>\n",
       "      <td>2958.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M33419717</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9920.52</td>\n",
       "      <td>C764826684</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M1940055334</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048545</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>7521.34</td>\n",
       "      <td>C1811303190</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M774310287</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048546</th>\n",
       "      <td>95</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2368.49</td>\n",
       "      <td>C855991004</td>\n",
       "      <td>289.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1932870004</td>\n",
       "      <td>666959.45</td>\n",
       "      <td>669327.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048547</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>12610.69</td>\n",
       "      <td>C212472829</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M1440565125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048548</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1759.86</td>\n",
       "      <td>C1134577600</td>\n",
       "      <td>34520.00</td>\n",
       "      <td>32760.14</td>\n",
       "      <td>M1537986282</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048549</th>\n",
       "      <td>95</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>9983.95</td>\n",
       "      <td>C130161561</td>\n",
       "      <td>997.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C740635949</td>\n",
       "      <td>2341925.24</td>\n",
       "      <td>2351909.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048550</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>2059.20</td>\n",
       "      <td>C941393291</td>\n",
       "      <td>25181.00</td>\n",
       "      <td>23121.80</td>\n",
       "      <td>M2034453263</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048551</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>14409.67</td>\n",
       "      <td>C2082080339</td>\n",
       "      <td>23121.80</td>\n",
       "      <td>8712.12</td>\n",
       "      <td>M1804850330</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048552</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>184.00</td>\n",
       "      <td>C939472062</td>\n",
       "      <td>107807.00</td>\n",
       "      <td>107623.00</td>\n",
       "      <td>M1418140285</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048553</th>\n",
       "      <td>95</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>103391.93</td>\n",
       "      <td>C2021893664</td>\n",
       "      <td>107623.00</td>\n",
       "      <td>4231.07</td>\n",
       "      <td>C178178755</td>\n",
       "      <td>5752648.68</td>\n",
       "      <td>5856040.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048554</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1075.92</td>\n",
       "      <td>C222403246</td>\n",
       "      <td>11199.00</td>\n",
       "      <td>10123.08</td>\n",
       "      <td>M1138038140</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048555</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11920.72</td>\n",
       "      <td>C804109193</td>\n",
       "      <td>20304.00</td>\n",
       "      <td>8383.28</td>\n",
       "      <td>M1245358834</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048556</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>6538.04</td>\n",
       "      <td>C1261428209</td>\n",
       "      <td>29467.00</td>\n",
       "      <td>22928.96</td>\n",
       "      <td>M549080861</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048557</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>25963.87</td>\n",
       "      <td>C1657375088</td>\n",
       "      <td>51929.00</td>\n",
       "      <td>25965.13</td>\n",
       "      <td>M2101072609</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048558</th>\n",
       "      <td>95</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>26535.41</td>\n",
       "      <td>C1213094114</td>\n",
       "      <td>104187.00</td>\n",
       "      <td>77651.59</td>\n",
       "      <td>C216374600</td>\n",
       "      <td>205460.26</td>\n",
       "      <td>231995.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048559</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>7986.90</td>\n",
       "      <td>C981349457</td>\n",
       "      <td>44696.00</td>\n",
       "      <td>36709.10</td>\n",
       "      <td>M349349991</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048560</th>\n",
       "      <td>95</td>\n",
       "      <td>CASH_IN</td>\n",
       "      <td>113412.53</td>\n",
       "      <td>C928894150</td>\n",
       "      <td>41533.00</td>\n",
       "      <td>154945.53</td>\n",
       "      <td>C1668344599</td>\n",
       "      <td>565908.33</td>\n",
       "      <td>452495.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048561</th>\n",
       "      <td>95</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>7880.88</td>\n",
       "      <td>C233708423</td>\n",
       "      <td>31489.00</td>\n",
       "      <td>23608.12</td>\n",
       "      <td>C794801857</td>\n",
       "      <td>18700000.00</td>\n",
       "      <td>18700000.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048562</th>\n",
       "      <td>95</td>\n",
       "      <td>CASH_IN</td>\n",
       "      <td>37644.42</td>\n",
       "      <td>C1182362327</td>\n",
       "      <td>102.00</td>\n",
       "      <td>37746.42</td>\n",
       "      <td>C2108562529</td>\n",
       "      <td>21209.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048563</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9414.75</td>\n",
       "      <td>C1206481903</td>\n",
       "      <td>20216.00</td>\n",
       "      <td>10801.25</td>\n",
       "      <td>M512470056</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048564</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>5227.49</td>\n",
       "      <td>C1665445469</td>\n",
       "      <td>21184.00</td>\n",
       "      <td>15956.51</td>\n",
       "      <td>M1852202800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>95</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>132387.24</td>\n",
       "      <td>C1654402840</td>\n",
       "      <td>15956.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1878219072</td>\n",
       "      <td>631284.08</td>\n",
       "      <td>763671.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048566</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>12598.15</td>\n",
       "      <td>C565523855</td>\n",
       "      <td>30601.00</td>\n",
       "      <td>18002.85</td>\n",
       "      <td>M1740980642</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>95</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>279674.05</td>\n",
       "      <td>C990252469</td>\n",
       "      <td>18002.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C574439165</td>\n",
       "      <td>1847488.28</td>\n",
       "      <td>2127162.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>20721.54</td>\n",
       "      <td>C954269986</td>\n",
       "      <td>49732.00</td>\n",
       "      <td>29010.46</td>\n",
       "      <td>M812667644</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>3210.11</td>\n",
       "      <td>C2113264897</td>\n",
       "      <td>11113.00</td>\n",
       "      <td>7902.89</td>\n",
       "      <td>M1989479599</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>95</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>132557.35</td>\n",
       "      <td>C1179511630</td>\n",
       "      <td>479803.00</td>\n",
       "      <td>347245.65</td>\n",
       "      <td>C435674507</td>\n",
       "      <td>484329.37</td>\n",
       "      <td>616886.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9917.36</td>\n",
       "      <td>C1956161225</td>\n",
       "      <td>90545.00</td>\n",
       "      <td>80627.64</td>\n",
       "      <td>M668364942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>14140.05</td>\n",
       "      <td>C2037964975</td>\n",
       "      <td>20545.00</td>\n",
       "      <td>6404.95</td>\n",
       "      <td>M1355182933</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>10020.05</td>\n",
       "      <td>C1633237354</td>\n",
       "      <td>90605.00</td>\n",
       "      <td>80584.95</td>\n",
       "      <td>M1964992463</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>95</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11450.03</td>\n",
       "      <td>C1264356443</td>\n",
       "      <td>80584.95</td>\n",
       "      <td>69134.92</td>\n",
       "      <td>M677577406</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step      type     amount     nameOrig  oldbalanceOrg  \\\n",
       "0           1   PAYMENT    9839.64  C1231006815      170136.00   \n",
       "1           1   PAYMENT    1864.28  C1666544295       21249.00   \n",
       "2           1  TRANSFER     181.00  C1305486145         181.00   \n",
       "3           1  CASH_OUT     181.00   C840083671         181.00   \n",
       "4           1   PAYMENT   11668.14  C2048537720       41554.00   \n",
       "5           1   PAYMENT    7817.71    C90045638       53860.00   \n",
       "6           1   PAYMENT    7107.77   C154988899      183195.00   \n",
       "7           1   PAYMENT    7861.64  C1912850431      176087.23   \n",
       "8           1   PAYMENT    4024.36  C1265012928        2671.00   \n",
       "9           1     DEBIT    5337.77   C712410124       41720.00   \n",
       "10          1     DEBIT    9644.94  C1900366749        4465.00   \n",
       "11          1   PAYMENT    3099.97   C249177573       20771.00   \n",
       "12          1   PAYMENT    2560.74  C1648232591        5070.00   \n",
       "13          1   PAYMENT   11633.76  C1716932897       10127.00   \n",
       "14          1   PAYMENT    4098.78  C1026483832      503264.00   \n",
       "15          1  CASH_OUT  229133.94   C905080434       15325.00   \n",
       "16          1   PAYMENT    1563.82   C761750706         450.00   \n",
       "17          1   PAYMENT    1157.86  C1237762639       21156.00   \n",
       "18          1   PAYMENT     671.64  C2033524545       15123.00   \n",
       "19          1  TRANSFER  215310.30  C1670993182         705.00   \n",
       "20          1   PAYMENT    1373.43    C20804602       13854.00   \n",
       "21          1     DEBIT    9302.79  C1566511282       11299.00   \n",
       "22          1     DEBIT    1065.41  C1959239586        1817.00   \n",
       "23          1   PAYMENT    3876.41   C504336483       67852.00   \n",
       "24          1  TRANSFER  311685.89  C1984094095       10835.00   \n",
       "25          1   PAYMENT    6061.13  C1043358826         443.00   \n",
       "26          1   PAYMENT    9478.39  C1671590089      116494.00   \n",
       "27          1   PAYMENT    8009.09  C1053967012       10968.00   \n",
       "28          1   PAYMENT    8901.99  C1632497828        2958.91   \n",
       "29          1   PAYMENT    9920.52   C764826684           0.00   \n",
       "...       ...       ...        ...          ...            ...   \n",
       "1048545    95   PAYMENT    7521.34  C1811303190           0.00   \n",
       "1048546    95     DEBIT    2368.49   C855991004         289.00   \n",
       "1048547    95   PAYMENT   12610.69   C212472829           0.00   \n",
       "1048548    95   PAYMENT    1759.86  C1134577600       34520.00   \n",
       "1048549    95     DEBIT    9983.95   C130161561         997.00   \n",
       "1048550    95   PAYMENT    2059.20   C941393291       25181.00   \n",
       "1048551    95   PAYMENT   14409.67  C2082080339       23121.80   \n",
       "1048552    95   PAYMENT     184.00   C939472062      107807.00   \n",
       "1048553    95  CASH_OUT  103391.93  C2021893664      107623.00   \n",
       "1048554    95   PAYMENT    1075.92   C222403246       11199.00   \n",
       "1048555    95   PAYMENT   11920.72   C804109193       20304.00   \n",
       "1048556    95   PAYMENT    6538.04  C1261428209       29467.00   \n",
       "1048557    95   PAYMENT   25963.87  C1657375088       51929.00   \n",
       "1048558    95  CASH_OUT   26535.41  C1213094114      104187.00   \n",
       "1048559    95   PAYMENT    7986.90   C981349457       44696.00   \n",
       "1048560    95   CASH_IN  113412.53   C928894150       41533.00   \n",
       "1048561    95     DEBIT    7880.88   C233708423       31489.00   \n",
       "1048562    95   CASH_IN   37644.42  C1182362327         102.00   \n",
       "1048563    95   PAYMENT    9414.75  C1206481903       20216.00   \n",
       "1048564    95   PAYMENT    5227.49  C1665445469       21184.00   \n",
       "1048565    95  TRANSFER  132387.24  C1654402840       15956.51   \n",
       "1048566    95   PAYMENT   12598.15   C565523855       30601.00   \n",
       "1048567    95  CASH_OUT  279674.05   C990252469       18002.85   \n",
       "1048568    95   PAYMENT   20721.54   C954269986       49732.00   \n",
       "1048569    95   PAYMENT    3210.11  C2113264897       11113.00   \n",
       "1048570    95  CASH_OUT  132557.35  C1179511630      479803.00   \n",
       "1048571    95   PAYMENT    9917.36  C1956161225       90545.00   \n",
       "1048572    95   PAYMENT   14140.05  C2037964975       20545.00   \n",
       "1048573    95   PAYMENT   10020.05  C1633237354       90605.00   \n",
       "1048574    95   PAYMENT   11450.03  C1264356443       80584.95   \n",
       "\n",
       "         newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  isFraud  \\\n",
       "0             160296.36  M1979787155            0.00            0.00        0   \n",
       "1              19384.72  M2044282225            0.00            0.00        0   \n",
       "2                  0.00   C553264065            0.00            0.00        1   \n",
       "3                  0.00    C38997010        21182.00            0.00        1   \n",
       "4              29885.86  M1230701703            0.00            0.00        0   \n",
       "5              46042.29   M573487274            0.00            0.00        0   \n",
       "6             176087.23   M408069119            0.00            0.00        0   \n",
       "7             168225.59   M633326333            0.00            0.00        0   \n",
       "8                  0.00  M1176932104            0.00            0.00        0   \n",
       "9              36382.23   C195600860        41898.00        40348.79        0   \n",
       "10                 0.00   C997608398        10845.00       157982.12        0   \n",
       "11             17671.03  M2096539129            0.00            0.00        0   \n",
       "12              2509.26   M972865270            0.00            0.00        0   \n",
       "13                 0.00   M801569151            0.00            0.00        0   \n",
       "14            499165.22  M1635378213            0.00            0.00        0   \n",
       "15                 0.00   C476402209         5083.00        51513.44        0   \n",
       "16                 0.00  M1731217984            0.00            0.00        0   \n",
       "17             19998.14  M1877062907            0.00            0.00        0   \n",
       "18             14451.36   M473053293            0.00            0.00        0   \n",
       "19                 0.00  C1100439041        22425.00            0.00        0   \n",
       "20             12480.57  M1344519051            0.00            0.00        0   \n",
       "21              1996.21  C1973538135        29832.00        16896.70        0   \n",
       "22               751.59   C515132998        10330.00            0.00        0   \n",
       "23             63975.59  M1404932042            0.00            0.00        0   \n",
       "24                 0.00   C932583850         6267.00      2719172.89        0   \n",
       "25                 0.00  M1558079303            0.00            0.00        0   \n",
       "26            107015.61    M58488213            0.00            0.00        0   \n",
       "27              2958.91   M295304806            0.00            0.00        0   \n",
       "28                 0.00    M33419717            0.00            0.00        0   \n",
       "29                 0.00  M1940055334            0.00            0.00        0   \n",
       "...                 ...          ...             ...             ...      ...   \n",
       "1048545            0.00   M774310287            0.00            0.00        0   \n",
       "1048546            0.00  C1932870004       666959.45       669327.94        0   \n",
       "1048547            0.00  M1440565125            0.00            0.00        0   \n",
       "1048548        32760.14  M1537986282            0.00            0.00        0   \n",
       "1048549            0.00   C740635949      2341925.24      2351909.19        0   \n",
       "1048550        23121.80  M2034453263            0.00            0.00        0   \n",
       "1048551         8712.12  M1804850330            0.00            0.00        0   \n",
       "1048552       107623.00  M1418140285            0.00            0.00        0   \n",
       "1048553         4231.07   C178178755      5752648.68      5856040.61        0   \n",
       "1048554        10123.08  M1138038140            0.00            0.00        0   \n",
       "1048555         8383.28  M1245358834            0.00            0.00        0   \n",
       "1048556        22928.96   M549080861            0.00            0.00        0   \n",
       "1048557        25965.13  M2101072609            0.00            0.00        0   \n",
       "1048558        77651.59   C216374600       205460.26       231995.66        0   \n",
       "1048559        36709.10   M349349991            0.00            0.00        0   \n",
       "1048560       154945.53  C1668344599       565908.33       452495.80        0   \n",
       "1048561        23608.12   C794801857     18700000.00     18700000.00        0   \n",
       "1048562        37746.42  C2108562529        21209.96            0.00        0   \n",
       "1048563        10801.25   M512470056            0.00            0.00        0   \n",
       "1048564        15956.51  M1852202800            0.00            0.00        0   \n",
       "1048565            0.00  C1878219072       631284.08       763671.32        0   \n",
       "1048566        18002.85  M1740980642            0.00            0.00        0   \n",
       "1048567            0.00   C574439165      1847488.28      2127162.32        0   \n",
       "1048568        29010.46   M812667644            0.00            0.00        0   \n",
       "1048569         7902.89  M1989479599            0.00            0.00        0   \n",
       "1048570       347245.65   C435674507       484329.37       616886.72        0   \n",
       "1048571        80627.64   M668364942            0.00            0.00        0   \n",
       "1048572         6404.95  M1355182933            0.00            0.00        0   \n",
       "1048573        80584.95  M1964992463            0.00            0.00        0   \n",
       "1048574        69134.92   M677577406            0.00            0.00        0   \n",
       "\n",
       "         isFlaggedFraud  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "5                     0  \n",
       "6                     0  \n",
       "7                     0  \n",
       "8                     0  \n",
       "9                     0  \n",
       "10                    0  \n",
       "11                    0  \n",
       "12                    0  \n",
       "13                    0  \n",
       "14                    0  \n",
       "15                    0  \n",
       "16                    0  \n",
       "17                    0  \n",
       "18                    0  \n",
       "19                    0  \n",
       "20                    0  \n",
       "21                    0  \n",
       "22                    0  \n",
       "23                    0  \n",
       "24                    0  \n",
       "25                    0  \n",
       "26                    0  \n",
       "27                    0  \n",
       "28                    0  \n",
       "29                    0  \n",
       "...                 ...  \n",
       "1048545               0  \n",
       "1048546               0  \n",
       "1048547               0  \n",
       "1048548               0  \n",
       "1048549               0  \n",
       "1048550               0  \n",
       "1048551               0  \n",
       "1048552               0  \n",
       "1048553               0  \n",
       "1048554               0  \n",
       "1048555               0  \n",
       "1048556               0  \n",
       "1048557               0  \n",
       "1048558               0  \n",
       "1048559               0  \n",
       "1048560               0  \n",
       "1048561               0  \n",
       "1048562               0  \n",
       "1048563               0  \n",
       "1048564               0  \n",
       "1048565               0  \n",
       "1048566               0  \n",
       "1048567               0  \n",
       "1048568               0  \n",
       "1048569               0  \n",
       "1048570               0  \n",
       "1048571               0  \n",
       "1048572               0  \n",
       "1048573               0  \n",
       "1048574               0  \n",
       "\n",
       "[1048575 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_fraud = pd.read_csv('PS_20174392719_1491204439457_log.csv')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "bank_fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By modern standards, it’s a relatively small dataset, with only 3,333 records, where each record uses 21 attributes to describe the profile of a customer of an unknown US mobile operator. The attributes are:\n",
    "\n",
    "- `State`: the US state in which the customer resides, indicated by a two-letter abbreviation; for example, OH or NJ\n",
    "- `Account Length`: the number of days that this account has been active\n",
    "- `Area Code`: the three-digit area code of the corresponding customer’s phone number\n",
    "- `Phone`: the remaining seven-digit phone number\n",
    "- `Int’l Plan`: whether the customer has an international calling plan: yes/no\n",
    "- `VMail Plan`: whether the customer has a voice mail feature: yes/no\n",
    "- `VMail Message`: presumably the average number of voice mail messages per month\n",
    "- `Day Mins`: the total number of calling minutes used during the day\n",
    "- `Day Calls`: the total number of calls placed during the day\n",
    "- `Day Charge`: the billed cost of daytime calls\n",
    "- `Eve Mins, Eve Calls, Eve Charge`: the billed cost for calls placed during the evening\n",
    "- `Night Mins`, `Night Calls`, `Night Charge`: the billed cost for calls placed during nighttime\n",
    "- `Intl Mins`, `Intl Calls`, `Intl Charge`: the billed cost for international calls\n",
    "- `CustServ Calls`: the number of calls placed to Customer Service\n",
    "- `Churn?`: whether the customer left the service: true/false\n",
    "\n",
    "The last attribute, `Churn?`, is known as the target attribute–the attribute that we want the ML model to predict.  Because the target attribute is binary, our model will be performing binary prediction, also known as binary classification.\n",
    "\n",
    "Let's begin exploring the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_fraud['isFlaggedFraud'].value_counts()\n",
    "bank_fraud = bank_fraud.drop(['isFlaggedFraud'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>% observations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CASH_IN</th>\n",
       "      <td>0.216608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CASH_OUT</th>\n",
       "      <td>0.356332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEBIT</th>\n",
       "      <td>0.006845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAYMENT</th>\n",
       "      <td>0.337480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRANSFER</th>\n",
       "      <td>0.082734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     % observations\n",
       "type                    \n",
       "CASH_IN         0.216608\n",
       "CASH_OUT        0.356332\n",
       "DEBIT           0.006845\n",
       "PAYMENT         0.337480\n",
       "TRANSFER        0.082734"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>% observations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nameOrig</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C1000001725</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000004530</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000008582</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000009135</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000012640</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000018663</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000022742</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000024318</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000025173</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000025399</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000028246</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100003513</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000035425</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000037689</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000039823</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000042392</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000044196</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000048260</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100005244</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000053329</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000053363</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000053637</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000055352</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100005571</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000058668</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000060941</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100006663</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100006673</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000070745</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000071455</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999951331</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999952707</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999953701</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999953972</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999954026</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999958235</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C99995839</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999959036</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999959052</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999961797</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999966551</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999968188</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999970182</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999972983</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999973405</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999974220</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999975542</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999976050</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C99997916</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999981753</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999981756</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999983233</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999983733</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999983894</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999985598</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999988902</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999989921</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999996950</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999998175</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C999999254</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048317 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        % observations\n",
       "nameOrig                   \n",
       "C1000001725    9.536752e-07\n",
       "C1000004530    9.536752e-07\n",
       "C1000008582    9.536752e-07\n",
       "C1000009135    9.536752e-07\n",
       "C1000012640    9.536752e-07\n",
       "C1000018663    9.536752e-07\n",
       "C1000022742    9.536752e-07\n",
       "C1000024318    9.536752e-07\n",
       "C1000025173    9.536752e-07\n",
       "C1000025399    9.536752e-07\n",
       "C1000028246    9.536752e-07\n",
       "C100003513     9.536752e-07\n",
       "C1000035425    9.536752e-07\n",
       "C1000037689    9.536752e-07\n",
       "C1000039823    9.536752e-07\n",
       "C1000042392    9.536752e-07\n",
       "C1000044196    9.536752e-07\n",
       "C1000048260    9.536752e-07\n",
       "C100005244     9.536752e-07\n",
       "C1000053329    9.536752e-07\n",
       "C1000053363    9.536752e-07\n",
       "C1000053637    9.536752e-07\n",
       "C1000055352    9.536752e-07\n",
       "C100005571     9.536752e-07\n",
       "C1000058668    9.536752e-07\n",
       "C1000060941    9.536752e-07\n",
       "C100006663     9.536752e-07\n",
       "C100006673     9.536752e-07\n",
       "C1000070745    9.536752e-07\n",
       "C1000071455    9.536752e-07\n",
       "...                     ...\n",
       "C999951331     9.536752e-07\n",
       "C999952707     9.536752e-07\n",
       "C999953701     9.536752e-07\n",
       "C999953972     9.536752e-07\n",
       "C999954026     9.536752e-07\n",
       "C999958235     9.536752e-07\n",
       "C99995839      9.536752e-07\n",
       "C999959036     9.536752e-07\n",
       "C999959052     9.536752e-07\n",
       "C999961797     9.536752e-07\n",
       "C999966551     9.536752e-07\n",
       "C999968188     9.536752e-07\n",
       "C999970182     9.536752e-07\n",
       "C999972983     9.536752e-07\n",
       "C999973405     9.536752e-07\n",
       "C999974220     9.536752e-07\n",
       "C999975542     9.536752e-07\n",
       "C999976050     9.536752e-07\n",
       "C99997916      9.536752e-07\n",
       "C999981753     9.536752e-07\n",
       "C999981756     9.536752e-07\n",
       "C999983233     9.536752e-07\n",
       "C999983733     9.536752e-07\n",
       "C999983894     9.536752e-07\n",
       "C999985598     9.536752e-07\n",
       "C999988902     9.536752e-07\n",
       "C999989921     9.536752e-07\n",
       "C999996950     9.536752e-07\n",
       "C999998175     9.536752e-07\n",
       "C999999254     9.536752e-07\n",
       "\n",
       "[1048317 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>% observations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nameDest</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C1000015936</th>\n",
       "      <td>8.583077e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000022185</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000030947</th>\n",
       "      <td>2.861026e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000038153</th>\n",
       "      <td>3.814701e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000038201</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000057469</th>\n",
       "      <td>1.907350e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000094209</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000104864</th>\n",
       "      <td>4.768376e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000113023</th>\n",
       "      <td>1.907350e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000124976</th>\n",
       "      <td>1.716615e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000151306</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000156006</th>\n",
       "      <td>2.384188e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000157415</th>\n",
       "      <td>1.811983e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000185448</th>\n",
       "      <td>1.907350e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000219612</th>\n",
       "      <td>1.239778e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10002438</th>\n",
       "      <td>6.675727e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000244012</th>\n",
       "      <td>4.768376e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000312792</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000314808</th>\n",
       "      <td>4.768376e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000322805</th>\n",
       "      <td>7.629402e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000351574</th>\n",
       "      <td>1.144410e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000358248</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000366880</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000374016</th>\n",
       "      <td>1.907350e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000389324</th>\n",
       "      <td>2.861026e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100042918</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000430395</th>\n",
       "      <td>2.861026e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C100045266</th>\n",
       "      <td>7.629402e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000469224</th>\n",
       "      <td>3.814701e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1000469870</th>\n",
       "      <td>2.384188e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999831159</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999832957</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999833536</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999834973</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M99985179</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M99985492</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999856682</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999865090</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999866909</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999869667</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999884110</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M99988804</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999894252</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999900872</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999902431</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999903220</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999905417</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999913116</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999917305</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999921450</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999925457</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999942490</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999942604</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999950506</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M99995342</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999968767</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999981724</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999989895</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999995419</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999996397</th>\n",
       "      <td>9.536752e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449635 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        % observations\n",
       "nameDest                   \n",
       "C1000015936    8.583077e-06\n",
       "C1000022185    9.536752e-07\n",
       "C1000030947    2.861026e-06\n",
       "C1000038153    3.814701e-06\n",
       "C1000038201    9.536752e-07\n",
       "C1000057469    1.907350e-06\n",
       "C1000094209    9.536752e-07\n",
       "C1000104864    4.768376e-06\n",
       "C1000113023    1.907350e-06\n",
       "C1000124976    1.716615e-05\n",
       "C1000151306    9.536752e-07\n",
       "C1000156006    2.384188e-05\n",
       "C1000157415    1.811983e-05\n",
       "C1000185448    1.907350e-06\n",
       "C1000219612    1.239778e-05\n",
       "C10002438      6.675727e-06\n",
       "C1000244012    4.768376e-06\n",
       "C1000312792    9.536752e-07\n",
       "C1000314808    4.768376e-06\n",
       "C1000322805    7.629402e-06\n",
       "C1000351574    1.144410e-05\n",
       "C1000358248    9.536752e-07\n",
       "C1000366880    9.536752e-07\n",
       "C1000374016    1.907350e-06\n",
       "C1000389324    2.861026e-06\n",
       "C100042918     9.536752e-07\n",
       "C1000430395    2.861026e-06\n",
       "C100045266     7.629402e-06\n",
       "C1000469224    3.814701e-06\n",
       "C1000469870    2.384188e-05\n",
       "...                     ...\n",
       "M999831159     9.536752e-07\n",
       "M999832957     9.536752e-07\n",
       "M999833536     9.536752e-07\n",
       "M999834973     9.536752e-07\n",
       "M99985179      9.536752e-07\n",
       "M99985492      9.536752e-07\n",
       "M999856682     9.536752e-07\n",
       "M999865090     9.536752e-07\n",
       "M999866909     9.536752e-07\n",
       "M999869667     9.536752e-07\n",
       "M999884110     9.536752e-07\n",
       "M99988804      9.536752e-07\n",
       "M999894252     9.536752e-07\n",
       "M999900872     9.536752e-07\n",
       "M999902431     9.536752e-07\n",
       "M999903220     9.536752e-07\n",
       "M999905417     9.536752e-07\n",
       "M999913116     9.536752e-07\n",
       "M999917305     9.536752e-07\n",
       "M999921450     9.536752e-07\n",
       "M999925457     9.536752e-07\n",
       "M999942490     9.536752e-07\n",
       "M999942604     9.536752e-07\n",
       "M999950506     9.536752e-07\n",
       "M99995342      9.536752e-07\n",
       "M999968767     9.536752e-07\n",
       "M999981724     9.536752e-07\n",
       "M999989895     9.536752e-07\n",
       "M999995419     9.536752e-07\n",
       "M999996397     9.536752e-07\n",
       "\n",
       "[449635 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.048575e+06</td>\n",
       "      <td>1.048575e+06</td>\n",
       "      <td>1.048575e+06</td>\n",
       "      <td>1.048575e+06</td>\n",
       "      <td>1.048575e+06</td>\n",
       "      <td>1.048575e+06</td>\n",
       "      <td>1.048575e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.696617e+01</td>\n",
       "      <td>1.586670e+05</td>\n",
       "      <td>8.740095e+05</td>\n",
       "      <td>8.938089e+05</td>\n",
       "      <td>9.781600e+05</td>\n",
       "      <td>1.114198e+06</td>\n",
       "      <td>1.089097e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.562325e+01</td>\n",
       "      <td>2.649409e+05</td>\n",
       "      <td>2.971751e+06</td>\n",
       "      <td>3.008271e+06</td>\n",
       "      <td>2.296780e+06</td>\n",
       "      <td>2.416593e+06</td>\n",
       "      <td>3.298351e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>1.214907e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>7.634333e+04</td>\n",
       "      <td>1.600200e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.263772e+05</td>\n",
       "      <td>2.182604e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>2.137619e+05</td>\n",
       "      <td>1.366420e+05</td>\n",
       "      <td>1.746000e+05</td>\n",
       "      <td>9.159235e+05</td>\n",
       "      <td>1.149808e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>3.890000e+07</td>\n",
       "      <td>3.890000e+07</td>\n",
       "      <td>4.210000e+07</td>\n",
       "      <td>4.220000e+07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               step        amount  oldbalanceOrg  newbalanceOrig  \\\n",
       "count  1.048575e+06  1.048575e+06   1.048575e+06    1.048575e+06   \n",
       "mean   2.696617e+01  1.586670e+05   8.740095e+05    8.938089e+05   \n",
       "std    1.562325e+01  2.649409e+05   2.971751e+06    3.008271e+06   \n",
       "min    1.000000e+00  1.000000e-01   0.000000e+00    0.000000e+00   \n",
       "25%    1.500000e+01  1.214907e+04   0.000000e+00    0.000000e+00   \n",
       "50%    2.000000e+01  7.634333e+04   1.600200e+04    0.000000e+00   \n",
       "75%    3.900000e+01  2.137619e+05   1.366420e+05    1.746000e+05   \n",
       "max    9.500000e+01  1.000000e+07   3.890000e+07    3.890000e+07   \n",
       "\n",
       "       oldbalanceDest  newbalanceDest       isFraud  \n",
       "count    1.048575e+06    1.048575e+06  1.048575e+06  \n",
       "mean     9.781600e+05    1.114198e+06  1.089097e-03  \n",
       "std      2.296780e+06    2.416593e+06  3.298351e-02  \n",
       "min      0.000000e+00    0.000000e+00  0.000000e+00  \n",
       "25%      0.000000e+00    0.000000e+00  0.000000e+00  \n",
       "50%      1.263772e+05    2.182604e+05  0.000000e+00  \n",
       "75%      9.159235e+05    1.149808e+06  0.000000e+00  \n",
       "max      4.210000e+07    4.220000e+07  1.000000e+00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x792 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Frequency tables for each categorical feature\n",
    "for column in bank_fraud.select_dtypes(include=['object']).columns:\n",
    "    display(pd.crosstab(index=bank_fraud[column], columns='% observations', normalize='columns'))\n",
    "\n",
    "# Histograms for each numeric features\n",
    "display(bank_fraud.describe())\n",
    "%matplotlib inline\n",
    "hist = bank_fraud.hist(bins=30, sharey=True, figsize=(11, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can see immediately that:\n",
    "- `State` appears to be quite evenly distributed\n",
    "- `Phone` takes on too many unique values to be of any practical use.  It's possible parsing out the prefix could have some value, but without more context on how these are allocated, we should avoid using it.\n",
    "- Only 14% of customers churned, so there is some class imabalance, but nothing extreme.\n",
    "- Most of the numeric features are surprisingly nicely distributed, with many showing bell-like gaussianity.  `VMail Message` being a notable exception (and `Area Code` showing up as a feature we should convert to non-numeric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bank_fraud = bank_fraud.drop('isFlaggedFraud', axis=1)\n",
    "#churn['Area Code'] = churn['Area Code'].astype(object)\n",
    "bank_fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's look at the relationship between each of the features and our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in bank_fraud.select_dtypes(include=['object']).columns:\n",
    "    if column != 'isFraud':\n",
    "        display(pd.crosstab(index=bank_fraud[column], columns=bank_fraud['isFraud'], normalize='columns'))\n",
    "\n",
    "for column in bank_fraud.select_dtypes(exclude=['object']).columns:\n",
    "    print(column)\n",
    "    hist = bank_fraud[[column, 'isFraud']].hist(by='isFraud', bins=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly we see that churners appear:\n",
    "- Fairly evenly distributed geographically\n",
    "- More likely to have an international plan\n",
    "- Less likely to have a voicemail plan\n",
    "- To exhibit some bimodality in daily minutes (either higher or lower than the average for non-churners)\n",
    "- To have a larger number of customer service calls (which makes sense as we'd expect customers who experience lots of problems may be more likely to churn)\n",
    "\n",
    "In addition, we see that churners take on very similar distributions for features like `Day Mins` and `Day Charge`.  That's not surprising as we'd expect minutes spent talking to correlate with charges.  Let's dig deeper into the relationships between our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bank_fraud.corr())\n",
    "pd.plotting.scatter_matrix(bank_fraud, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see several features that essentially have 100% correlation with one another.  Including these feature pairs in some machine learning algorithms can create catastrophic problems, while in others it will only introduce minor redundancy and bias.  Let's remove one feature from each of the highly correlated pairs: Day Charge from the pair with Day Mins, Night Charge from the pair with Night Mins, Intl Charge from the pair with Intl Mins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bank_fraud = bank_fraud.drop(['isFlaggedFraud'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've cleaned up our dataset, let's determine which algorithm to use.  As mentioned above, there appear to be some variables where both high and low (but not intermediate) values are predictive of churn.  In order to accommodate this in an algorithm like linear regression, we'd need to generate polynomial (or bucketed) terms.  Instead, let's attempt to model this problem using gradient boosted trees.  Amazon SageMaker provides an XGBoost container that we can use to train in a managed, distributed setting, and then host as a real-time prediction endpoint.  XGBoost uses gradient boosted trees which naturally account for non-linear relationships between features and the target variable, as well as accommodating complex interactions between features.\n",
    "\n",
    "Amazon SageMaker XGBoost can train on data in either a CSV or LibSVM format.  For this example, we'll stick with CSV.  It should:\n",
    "- Have the predictor variable in the first column\n",
    "- Not have a header row\n",
    "\n",
    "But first, let's convert our categorical features into numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1047433\n",
       "1       1142\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_fraud['isFraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_data = pd.get_dummies(bank_fraud)\n",
    "#bank_fraud.head()\n",
    "#df = pd.DataFrame(bank_fraud)\n",
    "#df.head()\n",
    "#bank_fraud = bank_fraud[['isFraud', 'step', 'nameOrig', 'amount']]\n",
    "#bank_fraud.head()\n",
    "model_data = pd.get_dummies(bank_fraud, columns=['type'])\n",
    "#model_data.head()\n",
    "#model_data = pd.concat([model_data['isFraud_True.'], model_data.drop(['isFraud_False.', 'isFraud_True.'], axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>type_CASH_IN</th>\n",
       "      <th>type_CASH_OUT</th>\n",
       "      <th>type_DEBIT</th>\n",
       "      <th>type_PAYMENT</th>\n",
       "      <th>type_TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
       "0     1   9839.64       170136.0       160296.36             0.0   \n",
       "1     1   1864.28        21249.0        19384.72             0.0   \n",
       "2     1    181.00          181.0            0.00             0.0   \n",
       "3     1    181.00          181.0            0.00         21182.0   \n",
       "4     1  11668.14        41554.0        29885.86             0.0   \n",
       "\n",
       "   newbalanceDest  isFraud  type_CASH_IN  type_CASH_OUT  type_DEBIT  \\\n",
       "0             0.0        0             0              0           0   \n",
       "1             0.0        0             0              0           0   \n",
       "2             0.0        1             0              0           0   \n",
       "3             0.0        1             0              1           0   \n",
       "4             0.0        0             0              0           0   \n",
       "\n",
       "   type_PAYMENT  type_TRANSFER  \n",
       "0             1              0  \n",
       "1             1              0  \n",
       "2             0              1  \n",
       "3             0              0  \n",
       "4             1              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = model_data.drop(['nameOrig', 'nameDest'], axis=1)\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = model_data.set_index('isFraud').reset_index()\n",
    "#cols = list(model_data.columns.values) \n",
    "#cols.pop(model_data.index('isFraud')) \n",
    "#model_data = model_data[['isFraud'] + cols] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's split the data into training, validation, and test sets.  This will help prevent us from overfitting the model, and allow us to test the models accuracy on data it hasn't already seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>type_CASH_IN</th>\n",
       "      <th>type_CASH_OUT</th>\n",
       "      <th>type_DEBIT</th>\n",
       "      <th>type_PAYMENT</th>\n",
       "      <th>type_TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud  step    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
       "0        0     1   9839.64       170136.0       160296.36             0.0   \n",
       "1        0     1   1864.28        21249.0        19384.72             0.0   \n",
       "2        1     1    181.00          181.0            0.00             0.0   \n",
       "3        1     1    181.00          181.0            0.00         21182.0   \n",
       "4        0     1  11668.14        41554.0        29885.86             0.0   \n",
       "\n",
       "   newbalanceDest  type_CASH_IN  type_CASH_OUT  type_DEBIT  type_PAYMENT  \\\n",
       "0             0.0             0              0           0             1   \n",
       "1             0.0             0              0           0             1   \n",
       "2             0.0             0              0           0             0   \n",
       "3             0.0             0              1           0             0   \n",
       "4             0.0             0              0           0             1   \n",
       "\n",
       "   type_TRANSFER  \n",
       "0              0  \n",
       "1              0  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data)), int(0.9 * len(model_data))])\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload these files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train\n",
    "\n",
    "Moving onto training, first we'll need to specify the locations of the XGBoost algorithm containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, because we're training with the CSV file format, we'll create `s3_input`s that our training function can use as a pointer to the files in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can specify a few parameters like what type of training instances we'd like to use and how many, as well as our XGBoost hyperparameters.  A few key hyperparameters are:\n",
    "- `max_depth` controls how deep each tree within the algorithm can be built.  Deeper trees can lead to better fit, but are more computationally expensive and can lead to overfitting.  There is typically some trade-off in model performance that needs to be explored between a large number of shallow trees and a smaller number of deeper trees.\n",
    "- `subsample` controls sampling of the training data.  This technique can help reduce overfitting, but setting it too low can also starve the model of data.\n",
    "- `num_round` controls the number of boosting rounds.  This is essentially the subsequent models that are trained using the residuals of previous iterations.  Again, more rounds should produce a better fit on the training data, but can be computationally expensive or lead to overfitting.\n",
    "- `eta` controls how aggressive each round of boosting is.  Larger values lead to more conservative boosting.\n",
    "- `gamma` controls how aggressively trees are grown.  Larger values lead to more conservative models.\n",
    "\n",
    "More detail on XGBoost's hyperparmeters can be found on their GitHub [page](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-02 15:00:03 Starting - Starting the training job...\n",
      "2019-05-02 15:00:05 Starting - Launching requested ML instances.........\n",
      "2019-05-02 15:01:46 Starting - Preparing the instances for training.........\n",
      "2019-05-02 15:03:32 Downloading - Downloading input data..\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[2019-05-02:15:03:43:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[31m[2019-05-02:15:03:43:INFO] File size need to be processed in the node: 47.88mb. Available memory size in the node: 8405.83mb\u001b[0m\n",
      "\u001b[31m[2019-05-02:15:03:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[15:03:43] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[15:03:43] 734002x11 matrix with 8074022 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[2019-05-02:15:03:43:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[31m[15:03:43] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[31m[15:03:44] 209715x11 matrix with 2306865 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[31m[15:03:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[0]#011train-error:0.000557#011validation-error:0.00061\u001b[0m\n",
      "\u001b[31m[15:03:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 2 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[1]#011train-error:0.000557#011validation-error:0.00061\u001b[0m\n",
      "\u001b[31m[15:03:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[2]#011train-error:0.000557#011validation-error:0.00061\u001b[0m\n",
      "\u001b[31m[15:03:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[3]#011train-error:0.000557#011validation-error:0.00061\u001b[0m\n",
      "\u001b[31m[15:03:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[4]#011train-error:0.000546#011validation-error:0.000601\u001b[0m\n",
      "\u001b[31m[15:03:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[5]#011train-error:0.00054#011validation-error:0.000591\u001b[0m\n",
      "\u001b[31m[15:03:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[6]#011train-error:0.000535#011validation-error:0.000582\u001b[0m\n",
      "\u001b[31m[15:03:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[7]#011train-error:0.000529#011validation-error:0.000563\u001b[0m\n",
      "\u001b[31m[15:03:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[8]#011train-error:0.000515#011validation-error:0.000553\u001b[0m\n",
      "\u001b[31m[15:03:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[9]#011train-error:0.000499#011validation-error:0.000544\u001b[0m\n",
      "\u001b[31m[15:03:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[10]#011train-error:0.000474#011validation-error:0.000505\u001b[0m\n",
      "\u001b[31m[15:03:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[11]#011train-error:0.000471#011validation-error:0.000501\u001b[0m\n",
      "\u001b[31m[15:03:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\n",
      "2019-05-02 15:03:43 Training - Training image download completed. Training in progress.\u001b[31m[12]#011train-error:0.000356#011validation-error:0.000415\u001b[0m\n",
      "\u001b[31m[15:03:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[13]#011train-error:0.000358#011validation-error:0.000415\u001b[0m\n",
      "\u001b[31m[15:03:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[14]#011train-error:0.000356#011validation-error:0.000415\u001b[0m\n",
      "\u001b[31m[15:03:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[15]#011train-error:0.000358#011validation-error:0.000415\u001b[0m\n",
      "\u001b[31m[15:03:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[16]#011train-error:0.00035#011validation-error:0.000396\u001b[0m\n",
      "\u001b[31m[15:03:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[17]#011train-error:0.000338#011validation-error:0.00041\u001b[0m\n",
      "\u001b[31m[15:03:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[18]#011train-error:0.000322#011validation-error:0.000381\u001b[0m\n",
      "\u001b[31m[15:03:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[19]#011train-error:0.000327#011validation-error:0.000377\u001b[0m\n",
      "\u001b[31m[15:03:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[20]#011train-error:0.000315#011validation-error:0.000381\u001b[0m\n",
      "\u001b[31m[15:03:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[21]#011train-error:0.000304#011validation-error:0.000358\u001b[0m\n",
      "\u001b[31m[15:03:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[22]#011train-error:0.000317#011validation-error:0.000396\u001b[0m\n",
      "\u001b[31m[15:03:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[23]#011train-error:0.000309#011validation-error:0.000396\u001b[0m\n",
      "\u001b[31m[15:03:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[24]#011train-error:0.000301#011validation-error:0.000391\u001b[0m\n",
      "\u001b[31m[15:03:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[25]#011train-error:0.000283#011validation-error:0.000362\u001b[0m\n",
      "\u001b[31m[15:03:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[26]#011train-error:0.000279#011validation-error:0.000358\u001b[0m\n",
      "\u001b[31m[15:03:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[27]#011train-error:0.00027#011validation-error:0.000348\u001b[0m\n",
      "\u001b[31m[15:03:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[28]#011train-error:0.000264#011validation-error:0.000339\u001b[0m\n",
      "\u001b[31m[15:03:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[29]#011train-error:0.000257#011validation-error:0.000339\u001b[0m\n",
      "\u001b[31m[15:03:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[30]#011train-error:0.000244#011validation-error:0.000329\u001b[0m\n",
      "\u001b[31m[15:03:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[31]#011train-error:0.000245#011validation-error:0.000329\u001b[0m\n",
      "\u001b[31m[15:03:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[32]#011train-error:0.000238#011validation-error:0.00031\u001b[0m\n",
      "\u001b[31m[15:03:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[33]#011train-error:0.000234#011validation-error:0.000296\u001b[0m\n",
      "\u001b[31m[15:03:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[34]#011train-error:0.000232#011validation-error:0.000296\u001b[0m\n",
      "\u001b[31m[15:03:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[35]#011train-error:0.000226#011validation-error:0.000286\u001b[0m\n",
      "\u001b[31m[15:03:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[36]#011train-error:0.000229#011validation-error:0.000291\u001b[0m\n",
      "\u001b[31m[15:03:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[37]#011train-error:0.000223#011validation-error:0.000281\u001b[0m\n",
      "\u001b[31m[15:03:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[38]#011train-error:0.000221#011validation-error:0.000272\u001b[0m\n",
      "\u001b[31m[15:03:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[39]#011train-error:0.000217#011validation-error:0.000281\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[15:03:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[40]#011train-error:0.000217#011validation-error:0.000272\u001b[0m\n",
      "\u001b[31m[15:04:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[41]#011train-error:0.000217#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[42]#011train-error:0.000217#011validation-error:0.000272\u001b[0m\n",
      "\u001b[31m[15:04:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[43]#011train-error:0.000217#011validation-error:0.000272\u001b[0m\n",
      "\u001b[31m[15:04:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[44]#011train-error:0.000215#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[45]#011train-error:0.000214#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[46]#011train-error:0.000213#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[47]#011train-error:0.000211#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[48]#011train-error:0.000211#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[49]#011train-error:0.00021#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 10 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[50]#011train-error:0.00021#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[51]#011train-error:0.00021#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[52]#011train-error:0.00021#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[53]#011train-error:0.00021#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[54]#011train-error:0.000203#011validation-error:0.000262\u001b[0m\n",
      "\u001b[31m[15:04:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[55]#011train-error:0.000204#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[56]#011train-error:0.000204#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[57]#011train-error:0.000199#011validation-error:0.000262\u001b[0m\n",
      "\u001b[31m[15:04:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[58]#011train-error:0.000195#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[59]#011train-error:0.000198#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[60]#011train-error:0.000193#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 20 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[61]#011train-error:0.000193#011validation-error:0.000262\u001b[0m\n",
      "\u001b[31m[15:04:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 22 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[62]#011train-error:0.000193#011validation-error:0.000267\u001b[0m\n",
      "\u001b[31m[15:04:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[63]#011train-error:0.000192#011validation-error:0.000253\u001b[0m\n",
      "\u001b[31m[15:04:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[64]#011train-error:0.000192#011validation-error:0.000253\u001b[0m\n",
      "\u001b[31m[15:04:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[65]#011train-error:0.000192#011validation-error:0.000253\u001b[0m\n",
      "\u001b[31m[15:04:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[66]#011train-error:0.000192#011validation-error:0.000253\u001b[0m\n",
      "\u001b[31m[15:04:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[67]#011train-error:0.000192#011validation-error:0.000257\u001b[0m\n",
      "\u001b[31m[15:04:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[68]#011train-error:0.000191#011validation-error:0.000262\u001b[0m\n",
      "\u001b[31m[15:04:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[69]#011train-error:0.000191#011validation-error:0.000262\u001b[0m\n",
      "\u001b[31m[15:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[70]#011train-error:0.000189#011validation-error:0.000257\u001b[0m\n",
      "\u001b[31m[15:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[71]#011train-error:0.000189#011validation-error:0.000248\u001b[0m\n",
      "\u001b[31m[15:04:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[72]#011train-error:0.000188#011validation-error:0.000248\u001b[0m\n",
      "\u001b[31m[15:04:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[73]#011train-error:0.000191#011validation-error:0.000248\u001b[0m\n",
      "\u001b[31m[15:04:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[74]#011train-error:0.000187#011validation-error:0.000243\u001b[0m\n",
      "\u001b[31m[15:04:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[75]#011train-error:0.000187#011validation-error:0.000248\u001b[0m\n",
      "\u001b[31m[15:04:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[31m[76]#011train-error:0.000187#011validation-error:0.000243\u001b[0m\n",
      "\u001b[31m[15:04:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[77]#011train-error:0.000187#011validation-error:0.000243\u001b[0m\n",
      "\u001b[31m[15:04:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[78]#011train-error:0.000185#011validation-error:0.000238\u001b[0m\n",
      "\u001b[31m[15:04:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[79]#011train-error:0.000185#011validation-error:0.000238\u001b[0m\n",
      "\u001b[31m[15:04:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[80]#011train-error:0.000187#011validation-error:0.000238\u001b[0m\n",
      "\u001b[31m[15:04:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[81]#011train-error:0.000184#011validation-error:0.000248\u001b[0m\n",
      "\u001b[31m[15:04:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[82]#011train-error:0.000185#011validation-error:0.000248\u001b[0m\n",
      "\u001b[31m[15:04:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[83]#011train-error:0.000185#011validation-error:0.000248\u001b[0m\n",
      "\u001b[31m[15:04:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[84]#011train-error:0.000185#011validation-error:0.000238\u001b[0m\n",
      "\u001b[31m[15:04:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[85]#011train-error:0.000181#011validation-error:0.000243\u001b[0m\n",
      "\u001b[31m[15:04:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[86]#011train-error:0.000178#011validation-error:0.000243\u001b[0m\n",
      "\u001b[31m[15:04:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[87]#011train-error:0.000176#011validation-error:0.000243\u001b[0m\n",
      "\u001b[31m[15:04:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[88]#011train-error:0.000176#011validation-error:0.000243\u001b[0m\n",
      "\u001b[31m[15:04:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[89]#011train-error:0.000176#011validation-error:0.000234\u001b[0m\n",
      "\u001b[31m[15:04:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 16 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[31m[90]#011train-error:0.000176#011validation-error:0.000234\u001b[0m\n",
      "\u001b[31m[15:04:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[91]#011train-error:0.000176#011validation-error:0.000234\u001b[0m\n",
      "\u001b[31m[15:04:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 22 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[92]#011train-error:0.000176#011validation-error:0.000234\u001b[0m\n",
      "\u001b[31m[15:04:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[93]#011train-error:0.000174#011validation-error:0.000234\u001b[0m\n",
      "\u001b[31m[15:04:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[94]#011train-error:0.000174#011validation-error:0.000234\u001b[0m\n",
      "\u001b[31m[15:04:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 20 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[95]#011train-error:0.000173#011validation-error:0.000238\u001b[0m\n",
      "\u001b[31m[15:04:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 22 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[96]#011train-error:0.000173#011validation-error:0.000238\u001b[0m\n",
      "\u001b[31m[15:04:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[31m[97]#011train-error:0.000173#011validation-error:0.000238\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-05-02 15:04:31 Uploading - Uploading generated training model\n",
      "2019-05-02 15:04:31 Completed - Training job completed\n",
      "\u001b[31m[15:04:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 20 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[31m[98]#011train-error:0.000172#011validation-error:0.000238\u001b[0m\n",
      "\u001b[31m[15:04:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[31m[99]#011train-error:0.00017#011validation-error:0.000238\u001b[0m\n",
      "Billable seconds: 59\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    base_job_name='nand',\n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Host\n",
    "\n",
    "Now that we've trained the algorithm, let's create a model and deploy it to a hosted endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Now that we have a hosted endpoint running, we can make real-time predictions from our model very easily, simply by making an http POST request.  But first, we'll need to setup serializers and deserializers for passing our `test_data` NumPy arrays to the model behind the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "xgb_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a simple function to:\n",
    "1. Loop over our test dataset\n",
    "1. Split it into mini-batches of rows \n",
    "1. Convert those mini-batchs to CSV string payloads\n",
    "1. Retrieve mini-batch predictions by invoking the XGBoost endpoint\n",
    "1. Collect predictions and convert from the CSV output our model provides into a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "predictions = predict(test_data.as_matrix()[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to compare the performance of a machine learning model, but let's start by simply by comparing actual to predicted values.  In this case, we're simply predicting whether the customer churned (`1`) or not (`0`), which produces a simple confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions     0.0  1.0\n",
       "actual                  \n",
       "0            104744    0\n",
       "1                23   91"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=test_data.iloc[:, 0], columns=np.round(predictions), rownames=['actual'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7982456140350878\n"
     ]
    }
   ],
   "source": [
    "recall = 91 / (91+23)\n",
    "print (recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "precision = 91/91\n",
    "print (precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nand-2019-05-02-15-00-03-264\n",
      "         isFraud  step     amount  oldbalanceOrg  newbalanceOrig  \\\n",
      "990133         0    45   32716.45        4502.00        37218.45   \n",
      "736408         0    38  161631.07       51270.00            0.00   \n",
      "743345         0    38  233275.88     8946978.38      9180254.25   \n",
      "636266         0    35    6608.72       17592.00        10983.28   \n",
      "649888         0    35   88629.22           0.00            0.00   \n",
      "192702         0    13   15766.53       20783.00         5016.47   \n",
      "5298           0     5    1553.21      129818.15       128264.94   \n",
      "1025777        0    48    2419.02       14166.57        11747.55   \n",
      "251081         0    14   90873.43     2869930.69      2960804.12   \n",
      "171422         0    12    8088.63           0.00            0.00   \n",
      "601985         0    34  702177.98       30009.00            0.00   \n",
      "75059          0    10    9477.57       94820.00        85342.43   \n",
      "770514         0    39    3425.39       88243.00        84817.61   \n",
      "954380         0    44   15083.15       59171.00        44087.85   \n",
      "814728         0    40   12026.07       22396.00        10369.93   \n",
      "896747         0    42   67992.52     3972945.49      4040938.01   \n",
      "61983          0     9  134807.29       60866.00            0.00   \n",
      "256690         0    14   18405.03           0.00            0.00   \n",
      "1014836        0    46    4237.22       20183.00        15945.78   \n",
      "969751         0    44   23101.48           0.00            0.00   \n",
      "542041         0    21   14944.11       25741.00        10796.89   \n",
      "551824         0    21  116989.21       23866.00            0.00   \n",
      "591407         0    33  310790.33           0.00            0.00   \n",
      "303943         0    15   10868.17      856039.94       845171.78   \n",
      "807525         0    40  297315.55      134636.58            0.00   \n",
      "696187         0    36  345357.87       35326.00            0.00   \n",
      "880529         0    42    2076.19           0.00            0.00   \n",
      "599979         0    33  436854.27      108476.00       545330.27   \n",
      "135310         0    11  340210.68       61963.00            0.00   \n",
      "593749         0    33  420565.85      779524.60      1200090.44   \n",
      "...          ...   ...        ...            ...             ...   \n",
      "987517         0    45  142990.70       38230.00            0.00   \n",
      "611994         0    34   45093.28           0.00            0.00   \n",
      "346508         0    16   56004.66           0.00            0.00   \n",
      "148347         0    12   15239.47           0.00            0.00   \n",
      "577904         0    33  226170.76           0.00            0.00   \n",
      "104396         0    10    9406.44       73612.16        64205.72   \n",
      "606003         0    34  278862.22       20660.00            0.00   \n",
      "1016211        0    47   11267.30       21468.00        10200.70   \n",
      "644396         0    35  312942.09     4528406.36      4841348.45   \n",
      "225494         0    14    9558.53      122142.64       112584.11   \n",
      "760747         0    38  188732.22      125265.00       313997.22   \n",
      "90451          0    10   13925.71        3193.00            0.00   \n",
      "224861         0    14  122372.73    12700000.00     12800000.00   \n",
      "1012079        0    46   11177.27           0.00            0.00   \n",
      "58569          0     9  175112.47     5874806.09      6049918.56   \n",
      "760553         0    38   97818.82     2457815.88      2555634.70   \n",
      "452004         0    19    3615.08       25860.00        22244.92   \n",
      "843355         0    41   69624.32       68027.00            0.00   \n",
      "525505         0    20  282164.63           0.00            0.00   \n",
      "633379         0    35  542082.82      363939.48            0.00   \n",
      "926011         0    43   33576.30       10827.00        44403.30   \n",
      "482137         0    19  275443.88      106277.00       381720.88   \n",
      "497549         0    20  232283.32    17200000.00     17400000.00   \n",
      "767043         0    39  182140.69           0.00            0.00   \n",
      "109950         0    11   51309.21     2152753.60      2204062.80   \n",
      "781845         0    39   79235.08           0.00            0.00   \n",
      "185893         0    13   75129.11           0.00            0.00   \n",
      "984307         0    45   12189.54      273121.71       260932.17   \n",
      "68710          0     9   11641.95           0.00            0.00   \n",
      "1677           0     1   12491.01           0.00            0.00   \n",
      "\n",
      "         oldbalanceDest  newbalanceDest  type_CASH_IN  type_CASH_OUT  \\\n",
      "990133             0.00            0.00             1              0   \n",
      "736408       1833009.55      1994640.62             0              1   \n",
      "743345        672832.94       439557.06             1              0   \n",
      "636266             0.00            0.00             0              0   \n",
      "649888       4936778.25      5025407.47             0              1   \n",
      "192702             0.00        15766.53             0              1   \n",
      "5298               0.00            0.00             0              0   \n",
      "1025777            0.00            0.00             0              0   \n",
      "251081        112327.34       264654.52             1              0   \n",
      "171422       1310336.46      1474035.78             0              1   \n",
      "601985             0.00       702177.98             0              1   \n",
      "75059              0.00            0.00             0              0   \n",
      "770514             0.00            0.00             0              0   \n",
      "954380             0.00            0.00             0              0   \n",
      "814728             0.00        12026.07             0              1   \n",
      "896747       2144271.40      2076278.87             1              0   \n",
      "61983         118192.61            0.00             0              0   \n",
      "256690             0.00            0.00             0              0   \n",
      "1014836            0.00            0.00             0              0   \n",
      "969751             0.00            0.00             0              0   \n",
      "542041             0.00            0.00             0              0   \n",
      "551824             0.00       116989.21             0              1   \n",
      "591407        364353.63       675143.96             0              1   \n",
      "303943             0.00            0.00             0              0   \n",
      "807525        765096.24      1062411.79             0              1   \n",
      "696187         10354.19       355712.05             0              1   \n",
      "880529             0.00            0.00             0              0   \n",
      "599979        149149.36            0.00             1              0   \n",
      "135310             0.00       561818.14             0              1   \n",
      "593749        646147.79       225581.94             1              0   \n",
      "...                 ...             ...           ...            ...   \n",
      "987517         98197.76       241188.46             0              1   \n",
      "611994       1293738.29      1338831.57             0              1   \n",
      "346508        344730.72       400735.37             0              1   \n",
      "148347       3527643.00      4028798.78             0              1   \n",
      "577904       1085898.87      1312069.63             0              1   \n",
      "104396             0.00            0.00             0              0   \n",
      "606003         66293.99       421127.98             0              1   \n",
      "1016211            0.00            0.00             0              0   \n",
      "644396       2789211.74      2476269.66             1              0   \n",
      "225494             0.00            0.00             0              0   \n",
      "760747             0.00            0.00             1              0   \n",
      "90451              0.00            0.00             0              0   \n",
      "224861        207439.31        85066.59             1              0   \n",
      "1012079            0.00            0.00             0              0   \n",
      "58569        1815456.55      2869868.36             1              0   \n",
      "760553       8001069.01      7903250.19             1              0   \n",
      "452004             0.00            0.00             0              0   \n",
      "843355         54081.23       123705.55             0              0   \n",
      "525505        284642.67       566807.30             0              1   \n",
      "633379        242327.30       784410.12             0              1   \n",
      "926011        317029.30       283453.00             1              0   \n",
      "482137          8439.00            0.00             1              0   \n",
      "497549        245101.00         3776.53             1              0   \n",
      "767043       1353358.00      1535498.69             0              1   \n",
      "109950        188041.00            0.00             1              0   \n",
      "781845        281701.47       360936.55             0              1   \n",
      "185893       2541198.42      2616327.53             0              1   \n",
      "984307             0.00            0.00             0              0   \n",
      "68710         475740.73       402380.36             0              1   \n",
      "1677               0.00            0.00             0              0   \n",
      "\n",
      "         type_DEBIT  type_PAYMENT  type_TRANSFER  \n",
      "990133            0             0              0  \n",
      "736408            0             0              0  \n",
      "743345            0             0              0  \n",
      "636266            0             1              0  \n",
      "649888            0             0              0  \n",
      "192702            0             0              0  \n",
      "5298              0             1              0  \n",
      "1025777           0             1              0  \n",
      "251081            0             0              0  \n",
      "171422            0             0              0  \n",
      "601985            0             0              0  \n",
      "75059             0             1              0  \n",
      "770514            0             1              0  \n",
      "954380            0             1              0  \n",
      "814728            0             0              0  \n",
      "896747            0             0              0  \n",
      "61983             0             0              1  \n",
      "256690            0             1              0  \n",
      "1014836           0             1              0  \n",
      "969751            0             1              0  \n",
      "542041            0             1              0  \n",
      "551824            0             0              0  \n",
      "591407            0             0              0  \n",
      "303943            0             1              0  \n",
      "807525            0             0              0  \n",
      "696187            0             0              0  \n",
      "880529            0             1              0  \n",
      "599979            0             0              0  \n",
      "135310            0             0              0  \n",
      "593749            0             0              0  \n",
      "...             ...           ...            ...  \n",
      "987517            0             0              0  \n",
      "611994            0             0              0  \n",
      "346508            0             0              0  \n",
      "148347            0             0              0  \n",
      "577904            0             0              0  \n",
      "104396            0             1              0  \n",
      "606003            0             0              0  \n",
      "1016211           0             1              0  \n",
      "644396            0             0              0  \n",
      "225494            0             1              0  \n",
      "760747            0             0              0  \n",
      "90451             0             1              0  \n",
      "224861            0             0              0  \n",
      "1012079           0             1              0  \n",
      "58569             0             0              0  \n",
      "760553            0             0              0  \n",
      "452004            0             1              0  \n",
      "843355            0             0              1  \n",
      "525505            0             0              0  \n",
      "633379            0             0              0  \n",
      "926011            0             0              0  \n",
      "482137            0             0              0  \n",
      "497549            0             0              0  \n",
      "767043            0             0              0  \n",
      "109950            0             0              0  \n",
      "781845            0             0              0  \n",
      "185893            0             0              0  \n",
      "984307            0             1              0  \n",
      "68710             0             0              0  \n",
      "1677              0             1              0  \n",
      "\n",
      "[104858 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print (xgb_predictor.endpoint)\n",
    "print (test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note, due to randomized elements of the algorithm, you results may differ slightly._\n",
    "\n",
    "Of the 48 churners, we've correctly predicted 39 of them (true positives). And, we incorrectly predicted 4 customers would churn who then ended up not doing so (false positives).  There are also 9 customers who ended up churning, that we predicted would not (false negatives).\n",
    "\n",
    "An important point here is that because of the `np.round()` function above we are using a simple threshold (or cutoff) of 0.5.  Our predictions from `xgboost` come out as continuous values between 0 and 1 and we force them into the binary classes that we began with.  However, because a customer that churns is expected to cost the company more than proactively trying to retain a customer who we think might churn, we should consider adjusting this cutoff.  That will almost certainly increase the number of false positives, but it can also be expected to increase the number of true positives and reduce the number of false negatives.\n",
    "\n",
    "To get a rough intuition here, let's look at the continuous values of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The continuous valued predictions coming from our model tend to skew toward 0 or 1, but there is sufficient mass between 0.1 and 0.9 that adjusting the cutoff should indeed shift a number of customers' predictions.  For example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFraud</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104742</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0         0   1\n",
       "isFraud            \n",
       "0        104742   2\n",
       "1            16  98"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=test_data.iloc[:, 0], columns=np.where(predictions > 0.26, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8448275862068966\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "recall = 98 / (98+18)\n",
    "print(recall)\n",
    "\n",
    "prediction = 98 / (98+2)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that changing the cutoff from 0.5 to 0.3 results in 1 more true positives, 3 more false positives, and 1 fewer false negatives.  The numbers are small overall here, but that's 6-10% of customers overall that are shifting because of a change to the cutoff.  Was this the right decision?  We may end up retaining 3 extra customers, but we also unnecessarily incentivized 5 more customers who would have stayed.  Determining optimal cutoffs is a key step in properly applying machine learning in a real-world setting.  Let's discuss this more broadly and then apply a specific, hypothetical solution for our current problem.\n",
    "\n",
    "### Relative cost of errors\n",
    "\n",
    "Any practical binary classification problem is likely to produce a similarly sensitive cutoff. That by itself isn’t a problem. After all, if the scores for two classes are really easy to separate, the problem probably isn’t very hard to begin with and might even be solvable with simple rules instead of ML.\n",
    "\n",
    "More important, if I put an ML model into production, there are costs associated with the model erroneously assigning false positives and false negatives. I also need to look at similar costs associated with correct predictions of true positives and true negatives.  Because the choice of the cutoff affects all four of these statistics, I need to consider the relative costs to the business for each of these four outcomes for each prediction.\n",
    "\n",
    "#### Assigning costs\n",
    "\n",
    "What are the costs for our problem of mobile operator churn? The costs, of course, depend on the specific actions that the business takes. Let's make some assumptions here.\n",
    "\n",
    "First, assign the true negatives the cost of \\$0. Our model essentially correctly identified a happy customer in this case, and we don’t need to do anything.\n",
    "\n",
    "False negatives are the most problematic, because they incorrectly predict that a churning customer will stay. We lose the customer and will have to pay all the costs of acquiring a replacement customer, including foregone revenue, advertising costs, administrative costs, point of sale costs, and likely a phone hardware subsidy. A quick search on the Internet reveals that such costs typically run in the hundreds of dollars so, for the purposes of this example, let's assume \\$500. This is the cost of false negatives.\n",
    "\n",
    "Finally, for customers that our model identifies as churning, let's assume a retention incentive in the amount of \\$100. If my provider offered me such a concession, I’d certainly think twice before leaving. This is the cost of both true positive and false positive outcomes. In the case of false positives (the customer is happy, but the model mistakenly predicted churn), we will “waste” the \\$100 concession. We probably could have spent that \\$100 more effectively, but it's possible we increased the loyalty of an already loyal customer, so that’s not so bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the optimal cutoff\n",
    "\n",
    "It’s clear that false negatives are substantially more costly than false positives. Instead of optimizing for error based on the number of customers, we should be minimizing a cost function that looks like this:\n",
    "\n",
    "```txt\n",
    "$500 * FN(C) + $0 * TN(C) + $100 * FP(C) + $100 * TP(C)\n",
    "```\n",
    "\n",
    "FN(C) means that the false negative percentage is a function of the cutoff, C, and similar for TN, FP, and TP.  We need to find the cutoff, C, where the result of the expression is smallest.\n",
    "\n",
    "A straightforward way to do this, is to simply run a simulation over a large number of possible cutoffs.  We test 100 possible values in the for loop below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is minimized near a cutoff of: 0.26 for a cost of: 18000\n"
     ]
    }
   ],
   "source": [
    "cutoffs = np.arange(0.01, 1, 0.01)\n",
    "costs = []\n",
    "for c in cutoffs:\n",
    "    costs.append(np.sum(np.sum(np.array([[0, 100], [500, 100]]) * \n",
    "                               pd.crosstab(index=test_data.iloc[:, 0], \n",
    "                                           columns=np.where(predictions > c, 1, 0)))))\n",
    "\n",
    "costs = np.array(costs)\n",
    "plt.plot(cutoffs, costs)\n",
    "plt.show()\n",
    "print('Cost is minimized near a cutoff of:', cutoffs[np.argmin(costs)], 'for a cost of:', np.min(costs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above chart shows how picking a threshold too low results in costs skyrocketing as all customers are given a retention incentive.  Meanwhile, setting the threshold too high results in too many lost customers, which ultimately grows to be nearly as costly.  The overall cost can be minimized at \\$8400 by setting the cutoff to 0.46, which is substantially better than the \\$20k+ I would expect to lose by not taking any action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extensions\n",
    "\n",
    "This notebook showcased how to build a model that predicts whether a customer is likely to churn, and then how to optimally set a threshold that accounts for the cost of true positives, false positives, and false negatives.  There are several means of extending it including:\n",
    "- Some customers who receive retention incentives will still churn.  Including a probability of churning despite receiving an incentive in our cost function would provide a better ROI on our retention programs.\n",
    "- Customers who switch to a lower-priced plan or who deactivate a paid feature represent different kinds of churn that could be modeled separately.\n",
    "- Modeling the evolution of customer behavior. If usage is dropping and the number of calls placed to Customer Service is increasing, you are more likely to experience churn then if the trend is the opposite. A customer profile should incorporate behavior trends.\n",
    "- Actual training data and monetary cost assignments could be more complex.\n",
    "- Multiple models for each type of churn could be needed.\n",
    "\n",
    "Regardless of additional complexity, similar principles described in this notebook are likely apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Clean-up\n",
    "\n",
    "If you're ready to be done with this notebook, please run the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
